<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI/ML Platform Adoption Research - Shikha Sharma</title>
  
  <!-- Import Inter font -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/inter-ui/3.19.3/inter.css" rel="stylesheet">
  
  <link rel="stylesheet" href="css/styles.css">
</head>
<body>
  <header>
    <div class="header-top">
      <div>
        <h1>Shikha Sharma</h1>
        <p class="subtitle">Strategic Mixed-Methods Researcher</p>
      </div>
      <div class="contact-info">
        <p>uxshikha@gmail.com</p>
        <p>(909) 569-7159</p>
        <p>linkedin.com/in/shikhasharma4</p>
      </div>
    </div>
  </header>
  
  <nav>
    <ul>
      <li><a href="index.html">Home</a></li>
      <li><a href="index.html#case-studies">Case Studies</a></li>
      <li><a href="index.html#approach">Research Approach</a></li>
      <li><a href="index.html#impact">Business Impact</a></li>
      <li><a href="index.html#contact">Contact</a></li>
    </ul>
  </nav>
  
  <section class="case-study-detail">
    <div class="case-hero">
      <h2>AI/ML Platform Adoption Research</h2>
      <p class="subtitle">Revealing the real drivers of ML platform adoption beyond infrastructure performance</p>
      <div class="tags">
        <span class="tag">AI/ML</span>
        <span class="tag">Platform Strategy</span>
        <span class="tag">User Research</span>
        <span class="tag">Post-Acquisition</span>
      </div>
    </div>
    
    <div class="case-section">
      <h3>Initial Situation</h3>
      <p>After acquiring Paperspace, DigitalOcean saw an opportunity to expand into the AI/ML space by leveraging its newly acquired GPU infrastructure. The internal assumption was clear: Top-tier hardware would attract ML developers. As investment planning began, this idea was gaining momentum — backed by a roadmap focused on compute performance, benchmarking, and instance types.</p>
      
      <p>But I knew from experience: adoption doesn't begin with specs. It begins with how developers think, learn, and build. So I reframed the research to ask a more consequential question: What actually drives ML developers to choose — and stick with — a cloud platform?</p>
    </div>
    
    <div class="case-section">
      <h3>Research Mission</h3>
      <p>Uncover what motivates AI/ML developers at each stage of their workflow:</p>
      <ul style="margin-left: var(--space-xl); margin-bottom: var(--space-md);">
        <li>What they look for when evaluating a platform</li>
        <li>What blocks their progress (technically and cognitively)</li>
        <li>What builds trust, fluency, and long-term usage</li>
        <li>How infrastructure capabilities intersect with usability, cost, and support</li>
      </ul>
    </div>
    
    <div class="case-section">
      <h3>Methodology</h3>
      <table class="methodology-table">
        <tr>
          <th>Phase</th>
          <th>Objective</th>
          <th>Method</th>
        </tr>
        <tr>
          <td>1. Stakeholder Alignment</td>
          <td>Surface existing assumptions across engineering and GTM</td>
          <td>SME and executive interviews</td>
        </tr>
        <tr>
          <td>2. Mental Model Mapping</td>
          <td>Understand how ML developers think about infrastructure</td>
          <td>Depth interviews + JTBD probing</td>
        </tr>
        <tr>
          <td>3. Contextual Inquiry</td>
          <td>Observe real-world AI/ML workflows</td>
          <td>Screen shares from dataset prep to deployment</td>
        </tr>
        <tr>
          <td>4. Behavioral Modeling</td>
          <td>Structure insights into motivational drivers and friction points</td>
          <td>COM-B + thematic clustering</td>
        </tr>
        <tr>
          <td>5. Segmentation & Synthesis</td>
          <td>Distill meaningful adoption patterns across maturity levels</td>
          <td>Persona tiering + insight frameworks</td>
        </tr>
      </table>
    </div>
    
    <div class="artifact-container artifact-detail">
      <div class="artifact-header">
        <h4>ML Platform Adoption Framework</h4>
        <span>Key Artifact</span>
      </div>
      
      <img src="artifacts/ml-adoption-framework.svg" alt="ML Platform Adoption Framework" class="artifact-img">
      
      <p><strong>Purpose:</strong> This framework juxtaposed organizational assumptions against user research findings to reveal the real drivers of ML platform adoption. It highlighted the gap between expected motivators (hardware specs) and actual motivators (workflow fit).</p>
      
      <p><strong>Impact:</strong> This artifact was instrumental in redirecting the product strategy from a hardware-centric approach to one focused on developer momentum and experience.</p>
    </div>
    
    <div class="case-section">
      <h3>Key Insights</h3>
      
      <div class="key-insights">
        <div class="insight-card">
          <h4>Workflow Fit > Hardware Specs</h4>
          <p>Developers didn't just want power — they wanted momentum. If setup, deployment, or scaling felt unpredictable, the power didn't matter.</p>
        </div>
        
        <div class="insight-card">
          <h4>Documentation Was a Strategic Asset</h4>
          <p>Even highly skilled ML engineers relied on templates, walkthroughs, and example repos. Developer self-sufficiency beat raw capability.</p>
        </div>
        
        <div class="insight-card">
          <h4>Support Ecosystem = Trust Layer</h4>
          <p>Users prioritized access to responsive support, Slack communities, and peers over pricing or brand. Confidence was social and cognitive, not just technical.</p>
        </div>
        
        <div class="insight-card">
          <h4>First Run Success Was the Real KPI</h4>
          <p>Platforms weren't judged by marketing claims — they were judged by how fast a user could go from concept to working model without needing to file a support ticket.</p>
        </div>
      </div>
    </div>
    
    <div class="case-section">
      <h3>Organizational Influence</h3>
      
      <div class="metrics">
        <p><strong>Resource Reallocation:</strong> $1M+ redirected from GPU benchmarking to docs, onboarding tooling, and community support</p>
        <p><strong>Performance Improvement:</strong> 35% increase in project starts, with first-run success up 40% after investment reallocation</p>
        <p><strong>Strategic Impact:</strong> Narrative shift from "GPU performance" to "developer success velocity" embedded across product and marketing</p>
      </div>
      
      <p>Strategic partnerships were formed with HuggingFace and DeepSeek based on integration and ecosystem, not hardware. This dramatically improved the adoption rate of the platform among AI/ML developers who were previously skeptical of a new entrant in the space.</p>
    </div>
    
    <div class="case-section">
      <h3>Reflection</h3>
      <p>This project reinforced a core belief I bring to all infrastructure research: Even the best hardware fails if the developer can't get through day one. My work revealed that DigitalOcean's competitive edge in AI/ML wasn't compute — it was approachability.</p>
      
      <p>And by exposing where adoption was stalling, we empowered the company to invest not in flashier specs, but in the scaffolding developers actually needed to move fast with confidence. This wasn't just a usability win. It was a strategic pivot that made the platform more credible, more usable, and more aligned with how ML is practiced — not just imagined.</p>
    </div>
    
    <div style="text-align: center; margin: var(--space-xl) 0;">
      <a href="index.html#case-studies" class="btn secondary">Back to Case Studies</a>
    </div>
  </section>
  
  <footer>
    <p>© 2025 Shikha Sharma — Strategic Mixed-Methods Researcher</p>
  </footer>
  
  <script src="js/main.js"></script>
</body>
</html>
